{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXWz060KVrCG"
      },
      "outputs": [],
      "source": [
        "!pip install flask\n",
        "!pip install flask-ngrok\n",
        "!pip install flask_restful\n",
        "!pip install werkzeug\n",
        "!pip install flask-cors\n",
        "from flask import Flask ,request,jsonify, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_restful import Resource, Api, reqparse\n",
        "import subprocess\n",
        "from flask_cors import CORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBUGfaUTGrPw",
        "outputId": "5abc2e30-c019-456c-f7d8-5d92a9272d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPbp34BoiMDK"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5uZUI1gj9M5o",
        "outputId": "d53dfe1a-326c-4c40-cb18-d9687c8ed977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/thin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.copytree(\"/content/drive/MyDrive/thin\", \"/content/thin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8VkBp8B9_Ol",
        "outputId": "184222ca-d4b8-49ed-d7fa-f4f3d1bf30b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/thin\n"
          ]
        }
      ],
      "source": [
        "cd thin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3fi9vqMBcTm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# edit the config\n",
        "device = torch.device('cuda:0')\n",
        "predict_mode = 'relative' # ['standard', 'relative', 'avd']\n",
        "find_best_frame = False # when use the relative mode to animate a face, use 'find_best_frame=True' can get better quality result\n",
        "if find_best_frame:\n",
        "  !pip install face_alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VR5OVQWZJXW"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "try:\n",
        "      import imageio\n",
        "      import imageio_ffmpeg\n",
        "except:\n",
        "  !pip install imageio_ffmpeg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hYpSOffUnMeP",
        "outputId": "48aaea12-a95e-4d9f-a684-29bc5fbc6711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/thin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp \"/content/drive/MyDrive/DemoConfig/mgif_taichi_thin_plate.yaml\"  /content/thin/config"
      ],
      "metadata": {
        "id": "R5PlCt7mfWMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcPl4A2jnSfN"
      },
      "outputs": [],
      "source": [
        "cp \"/content/drive/MyDrive/DemoConfig/fashion_taichi_thin_plate.yaml\"  /content/thin/config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISylyazyEiMa"
      },
      "outputs": [],
      "source": [
        "import thin.demo\n",
        "inpaintingFashion, kp_detectorFashion, dense_motion_networkFashion, avd_networkFashion = thin.demo.load_checkpoints(config_path = '/content/thin/config/fashion_taichi_thin_plate.yaml', checkpoint_path = '/content/drive/MyDrive/Fashion_Taichi_ThinPlate/00000033-checkpoint.pth.tar', device = device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import thin.demo\n",
        "inpaintingGif, kp_detectorGif, dense_motion_networkGif, avd_networkGif = thin.demo.load_checkpoints(config_path = '/content/thin/config/mgif_taichi_thin_plate.yaml', checkpoint_path = '/content/drive/MyDrive/MGIF_Taichi_ThinPlate/00000032-checkpoint.pth.tar', device = device)"
      ],
      "metadata": {
        "id": "LoBtp8mUf3v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXETm-dWmcp",
        "outputId": "3567e6ec-68e9-43a4-a6c8-a8722c40b75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViBUkd3MpMUD",
        "outputId": "12b2df8d-e71f-4f88-da89-8db3f3ec61ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LIA'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 95 (delta 17), reused 15 (delta 15), pack-reused 73\u001b[K\n",
            "Unpacking objects: 100% (95/95), 21.49 MiB | 9.25 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wyhsirius/LIA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/LIA/run_demo.py"
      ],
      "metadata": {
        "id": "yfOWMhFQq9-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp \"/content/drive/MyDrive/run_demo.py\"  /content/LIA"
      ],
      "metadata": {
        "id": "CuXpmwlWqpZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vjjyK9IpVIT"
      },
      "outputs": [],
      "source": [
        "cp \"/content/drive/MyDrive/fashion_tarining/taichi/checkpoint/27.pt\"  /content/LIA/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp \"/content/drive/MyDrive/mgif_tarining/taichi/checkpoint/30.pt\"  /content/LIA/checkpoints"
      ],
      "metadata": {
        "id": "PD761gBQcgYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1f80HcUH3yA"
      },
      "outputs": [],
      "source": [
        "#ted if fashion, taichi if mgif\n",
        "import os\n",
        "old_name = r\"/content/LIA/checkpoints/30.pt\"\n",
        "new_name = r\"/content/LIA/checkpoints/gif.pt\"\n",
        "os.rename(old_name, new_name)\n",
        "old_name = r\"/content/LIA/checkpoints/27.pt\"\n",
        "new_name = r\"/content/LIA/checkpoints/fashion.pt\"\n",
        "os.rename(old_name, new_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miVivUWDpVh7",
        "outputId": "93caec03-b64f-422b-b585-6ae7831560dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting av\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-10.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install av"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-_pvw12-1hu3",
        "outputId": "944c11ee-6f0c-4c73-e453-8ee3c41ec828"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D14MhpuSpiov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811455af-8d64-432b-9253-7d2eab66288c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://fb53-34-143-146-88.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "Ana fel function\n",
            "fashion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 425/425 [00:30<00:00, 13.97it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [08/May/2023 14:19:23] \"POST /post HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n",
            "Ana fel function\n",
            "fashion\n",
            "here\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/May/2023 14:20:44] \"POST /post HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "Success\n",
            "Ana fel function\n",
            "gif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:01<00:00, 13.14it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [08/May/2023 14:21:12] \"POST /post HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n",
            "Ana fel function\n",
            "gif\n",
            "here\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/May/2023 14:21:33] \"POST /post HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "Success\n"
          ]
        }
      ],
      "source": [
        "server = Flask (__name__)\n",
        "run_with_ngrok(server)\n",
        "CORS(server)\n",
        "\n",
        "\n",
        "@server.route('/post', methods=['POST'])\n",
        "def get_Image_Video():\n",
        "\n",
        "  pixel = 256\n",
        "  print(\"Ana fel function\")\n",
        "  image = request.files['Image']\n",
        "  video = request.files['Video']\n",
        "  model = request.form.get('Model') # Fetch the radio button value\n",
        "  dataset = request.form.get('Dataset')\n",
        "  print(dataset)\n",
        "\n",
        "  image.save(\"/content/imagetest.jpeg\")\n",
        "  video.save(\"/content/videotest.mp4\")\n",
        "  source_image_path = '/content/imagetest.jpeg'\n",
        "  driving_video_path = '/content/videotest.mp4'\n",
        "  output_video_path = '/content/imagetest_videotest.mp4'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  if(model == 'Thin'):\n",
        "    source_image = imageio.imread(source_image_path)\n",
        "    reader = imageio.get_reader(driving_video_path)\n",
        "    source_image = resize(source_image, (pixel, pixel))[..., :3]\n",
        "    if(dataset == 'fashion'):\n",
        "      fps = reader.get_meta_data()['fps']\n",
        "    driving_video = []\n",
        "    try:\n",
        "        for im in reader:\n",
        "            driving_video.append(im)\n",
        "    except RuntimeError:\n",
        "        pass\n",
        "    reader.close()\n",
        "    driving_video = [resize(frame, (pixel, pixel))[..., :3] for frame in driving_video]\n",
        "\n",
        "    from thin.demo import make_animation\n",
        "    from skimage import img_as_ubyte\n",
        "    if predict_mode=='relative' and find_best_frame:\n",
        "        from thin.demo import find_best_frame as _find\n",
        "        i = _find(source_image, driving_video, device.type=='cpu')\n",
        "        print (\"Best frame: \" + str(i))\n",
        "        driving_forward = driving_video[i:]\n",
        "        driving_backward = driving_video[:(i+1)][::-1]\n",
        "        if(dataset == 'fashion'):\n",
        "          fps = reader.get_meta_data()['fps']\n",
        "          predictions_forward = make_animation(source_image, driving_forward, inpaintingFashion, kp_detectorFashion, dense_motion_networkFashion, avd_networkFashion, device = device, mode = predict_mode)\n",
        "          predictions_backward = make_animation(source_image, driving_backward, inpaintingFashion, kp_detectorFashion, dense_motion_networkFashion, avd_networkFashion, device = device, mode = predict_mode)\n",
        "        else:\n",
        "          predictions_forward = make_animation(source_image, driving_forward, inpaintingGif, kp_detectorGif, dense_motion_networkGif, avd_networkGif, device = device, mode = predict_mode)\n",
        "          predictions_backward = make_animation(source_image, driving_backward, inpaintingGif, kp_detectorGif, dense_motion_networkGif, avd_networkGif, device = device, mode = predict_mode)\n",
        "        predictions = predictions_backward[::-1] + predictions_forward[1:]\n",
        "    else:\n",
        "      if(dataset == 'fashion'):\n",
        "        predictions = make_animation(source_image, driving_video, inpaintingFashion, kp_detectorFashion, dense_motion_networkFashion, avd_networkFashion, device = device, mode = predict_mode)\n",
        "      else:\n",
        "        predictions = make_animation(source_image, driving_video, inpaintingGif, kp_detectorGif, dense_motion_networkGif, avd_networkGif, device = device, mode = predict_mode)\n",
        "\n",
        "    #save resulting video\n",
        "    if(dataset == 'fashion'):\n",
        "      imageio.mimsave(output_video_path, [img_as_ubyte(frame) for frame in predictions], fps = fps)\n",
        "    else:\n",
        "      imageio.mimsave(output_video_path, [img_as_ubyte(frame) for frame in predictions])\n",
        "\n",
        "    \n",
        "  elif model == 'Latent':\n",
        "    os.chdir(\"/content/LIA\")\n",
        "    print(\"here\")\n",
        "    if(dataset == \"fashion\"):\n",
        "      subprocess.call([\"python\", \"run_demo.py\", \"--model\", \"fashion\", \"--source_path\", source_image_path, \"--driving_path\", driving_video_path])\n",
        "      print(\"done\")\n",
        "      output_video_path = \"/content/LIA/res/fashion/imagetest_videotest.mp4\"\n",
        "    elif(dataset == \"gif\"):\n",
        "      subprocess.call([\"python\", \"run_demo.py\", \"--model\", \"gif\", \"--source_path\", source_image_path, \"--driving_path\", driving_video_path])\n",
        "      print(\"done\")\n",
        "      output_video_path = \"/content/LIA/res/gif/imagetest_videotest.mp4\"\n",
        "  \n",
        "  if os.path.exists(output_video_path):\n",
        "      print(\"Success\")\n",
        "      return send_file(output_video_path)\n",
        "  else:\n",
        "      return 'Error'\n",
        "\n",
        "\n",
        "server.run()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}